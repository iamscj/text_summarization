{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN65iRr/nCzGsioK1Giu5Of",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iamscj/text_summarization/blob/main/text_summarization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RUpXPVIRxFNK"
      },
      "outputs": [],
      "source": [
        "import spacy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytextrank\n",
        "import pytextrank"
      ],
      "metadata": {
        "id": "kT0X4cvv0EyH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy.cli\n",
        "spacy.cli.download(\"en_core_web_lg\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wAORCi80nw6",
        "outputId": "814a80f0-8bbb-403c-a73b-f9e4de7cfc6a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_lg')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"en_core_web_lg\")"
      ],
      "metadata": {
        "id": "Li2ePwnM0dnk"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp.add_pipe(\"textrank\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AqhEOvwN1SkI",
        "outputId": "d43778e7-dd79-4658-c7ba-cd91ff363d59"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pytextrank.base.BaseTextRankFactory at 0x799a9e00ffa0>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_text = \"\"\"Deep learning (also known as deep structured learning) is part of a broader family of machine learning methods based on artificial neural networks with representation learning. Learning can be supervised, semi-supervised or unsupervised. Deep-learning architectures such as deep neural networks, deep belief networks, deep reinforcement learning, recurrent neural networks and convolutional neural networks have been applied to fields including computer vision, speech recognition, natural language processing, machine translation, bioinformatics, drug design, medical image analysis, material inspection and board game programs, where they have produced results comparable to and in some cases surpassing human expert performance. Artificial neural networks (ANNs) were inspired by information processing and distributed communication nodes in biological systems. ANNs have various differences from biological brains. Specifically, neural networks tend to be static and symbolic, while the biological brain of most living organisms is dynamic (plastic) and analogue. The adjective \"deep\" in deep learning refers to the use of multiple layers in the network. Early work showed that a linear perceptron cannot be a universal classifier, but that a network with a nonpolynomial activation function with one hidden layer of unbounded width can. Deep learning is a modern variation which is concerned with an unbounded number of layers of bounded size, which permits practical application and optimized implementation, while retaining theoretical universality under mild conditions. In deep learning the layers are also permitted to be heterogeneous and to deviate widely from biologically informed connectionist models, for the sake of efficiency, trainability and understandability, whence the structured part.\"\"\""
      ],
      "metadata": {
        "id": "x52uauq_1hwB"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "mo98GV_j1yZ7",
        "outputId": "a12791ee-18ec-4377-e24b-2913f8ea51cb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Deep learning (also known as deep structured learning) is part of a broader family of machine learning methods based on artificial neural networks with representation learning. Learning can be supervised, semi-supervised or unsupervised. Deep-learning architectures such as deep neural networks, deep belief networks, deep reinforcement learning, recurrent neural networks and convolutional neural networks have been applied to fields including computer vision, speech recognition, natural language processing, machine translation, bioinformatics, drug design, medical image analysis, material inspection and board game programs, where they have produced results comparable to and in some cases surpassing human expert performance. Artificial neural networks (ANNs) were inspired by information processing and distributed communication nodes in biological systems. ANNs have various differences from biological brains. Specifically, neural networks tend to be static and symbolic, while the biological brain of most living organisms is dynamic (plastic) and analogue. The adjective \"deep\" in deep learning refers to the use of multiple layers in the network. Early work showed that a linear perceptron cannot be a universal classifier, but that a network with a nonpolynomial activation function with one hidden layer of unbounded width can. Deep learning is a modern variation which is concerned with an unbounded number of layers of bounded size, which permits practical application and optimized implementation, while retaining theoretical universality under mild conditions. In deep learning the layers are also permitted to be heterogeneous and to deviate widely from biologically informed connectionist models, for the sake of efficiency, trainability and understandability, whence the structured part.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(example_text)"
      ],
      "metadata": {
        "id": "vyzAe5bu18fg"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for sent in doc._.textrank.summary(limit_phrases=2, limit_sentences=2):\n",
        "      print(sent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eqm5az8o2hjx",
        "outputId": "f87c6484-bfeb-4adb-d762-a8637d11a5c2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deep-learning architectures such as deep neural networks, deep belief networks, deep reinforcement learning, recurrent neural networks and convolutional neural networks have been applied to fields including computer vision, speech recognition, natural language processing, machine translation, bioinformatics, drug design, medical image analysis, material inspection and board game programs, where they have produced results comparable to and in some cases surpassing human expert performance.\n",
            "Specifically, neural networks tend to be static and symbolic, while the biological brain of most living organisms is dynamic (plastic) and analogue.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "phrases_and_ranks = [\n",
        "    (phrase.chunks[0], phrase.rank) for phrase in doc._.phrases\n",
        "]\n",
        "phrases_and_ranks[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G9GCL4Ut2mQU",
        "outputId": "2f16747e-87e9-4e9b-c568-8bcab8c87bb8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(deep neural networks, 0.10364509849008059),\n",
              " (neural networks, 0.10102404523282779),\n",
              " (Artificial neural networks, 0.09989699470448424),\n",
              " (artificial neural networks, 0.09989699470448424),\n",
              " (convolutional neural networks, 0.09769920802994711),\n",
              " (recurrent neural networks, 0.09713667609813895),\n",
              " (machine learning methods, 0.09666098636117204),\n",
              " (deep structured learning, 0.09423881883106089),\n",
              " (human expert performance, 0.09239148946068786),\n",
              " (deep belief networks, 0.0910797256886126)]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install sentencepiece"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBjgKwJGJLF_",
        "outputId": "eb99f27b-8d02-411e-ced0-3bae14eec479"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.30.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.16.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.96)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import PegasusForConditionalGeneration\n",
        "from transformers import PegasusTokenizer\n",
        "from transformers import pipeline\n",
        "import sentencepiece"
      ],
      "metadata": {
        "id": "AG1ABMmO3QGn"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pick model\n",
        "model_name = \"google/pegasus-xsum\"\n",
        "\n",
        "# Load pretrained tokenizer\n",
        "pegasus_tokenizer = PegasusTokenizer.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "7M5q68TIHG-7"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define PEGASUS model\n",
        "pegasus_model = PegasusForConditionalGeneration.from_pretrained(model_name)\n",
        "\n",
        "# Create tokens\n",
        "tokens = pegasus_tokenizer(example_text, truncation=True, padding=\"longest\", return_tensors=\"pt\")"
      ],
      "metadata": {
        "id": "BXqcqt3AJTZg"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Summarize text\n",
        "encoded_summary = pegasus_model.generate(**tokens)\n",
        "\n",
        "# Decode summarized text\n",
        "decoded_summary = pegasus_tokenizer.decode(\n",
        "      encoded_summary[0],\n",
        "      skip_special_tokens=True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQJ-iBlaKNv6",
        "outputId": "d343677a-3221-495c-b4b8-4b1555122efe"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1353: UserWarning: Using `max_length`'s default (64) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define summarization pipeline\n",
        "summarizer = pipeline(\n",
        "    \"summarization\",\n",
        "    model=model_name,\n",
        "    tokenizer=pegasus_tokenizer,\n",
        "    framework=\"pt\"\n",
        ")"
      ],
      "metadata": {
        "id": "lcY1eg75KhAb"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_text = \"\"\"Abu'l-Fath Jalal-ud-din Muhammad Akbar[9] (15 October 1542[a] – 27 October 1605),[12][13][14] popularly known as Akbar the Great[15] (Persian pronunciation: [akbarɪ azam]), and also as Akbar I (Persian pronunciation: [akbar]),[16] was the third Mughal emperor, who reigned from 1556 to 1605. Akbar succeeded his father, Humayun, under a regent, Bairam Khan, who helped the young emperor expand and consolidate Mughal domains in the Indian subcontinent.\n",
        "\n",
        "Akbar gradually enlarged the Mughal Empire to include much of the Indian subcontinent through Mughal military, political, cultural, and economic dominance. To unify the vast Mughal state, Akbar established a centralised system of administration and adopted a policy of conciliating conquered rulers through marriage and diplomacy. To preserve peace and order in a religiously and culturally diverse empire, he adopted policies that won him the support of his non-Muslim subjects, including abolishing the sectarian tax and appointing them to high civil and military posts.\n",
        "\n",
        "Under Akbar, Mughal India developed a strong and stable economy, which tripled in size and wealth, leading to commercial expansion and greater patronage of an Indo-Persian culture. Akbar's courts at Delhi, Agra, and Fatehpur Sikri attracted holy men of many faiths, poets, architects, and artisans, and become known as centres of the arts, letters, and learning. Timurid and Perso-Islamic culture began to merge and blend with indigenous Indian elements into a distinct style of Mughal arts, including painting and architecture. Disillusioned with orthodox Islam and perhaps hoping to bring about religious unity within his empire, Akbar promulgated Din-i Ilahi, a syncretic creed derived mainly from Islam and Hinduism as well as elements of Zoroastrianism and Christianity.\n",
        "\n",
        "Akbar was succeeded as emperor by his son, Prince Salim, later known as Jahangir.\"\"\""
      ],
      "metadata": {
        "id": "TL3LuSnpK8oM"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "eeVp4-h9LT_B",
        "outputId": "c5d58f3e-4fcb-4673-fce3-d930666ee405"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Abu'l-Fath Jalal-ud-din Muhammad Akbar[9] (15 October 1542[a] – 27 October 1605),[12][13][14] popularly known as Akbar the Great[15] (Persian pronunciation: [akbarɪ azam]), and also as Akbar I (Persian pronunciation: [akbar]),[16] was the third Mughal emperor, who reigned from 1556 to 1605. Akbar succeeded his father, Humayun, under a regent, Bairam Khan, who helped the young emperor expand and consolidate Mughal domains in the Indian subcontinent.\\n\\nAkbar gradually enlarged the Mughal Empire to include much of the Indian subcontinent through Mughal military, political, cultural, and economic dominance. To unify the vast Mughal state, Akbar established a centralised system of administration and adopted a policy of conciliating conquered rulers through marriage and diplomacy. To preserve peace and order in a religiously and culturally diverse empire, he adopted policies that won him the support of his non-Muslim subjects, including abolishing the sectarian tax and appointing them to high civil and military posts.\\n\\nUnder Akbar, Mughal India developed a strong and stable economy, which tripled in size and wealth, leading to commercial expansion and greater patronage of an Indo-Persian culture. Akbar's courts at Delhi, Agra, and Fatehpur Sikri attracted holy men of many faiths, poets, architects, and artisans, and become known as centres of the arts, letters, and learning. Timurid and Perso-Islamic culture began to merge and blend with indigenous Indian elements into a distinct style of Mughal arts, including painting and architecture. Disillusioned with orthodox Islam and perhaps hoping to bring about religious unity within his empire, Akbar promulgated Din-i Ilahi, a syncretic creed derived mainly from Islam and Hinduism as well as elements of Zoroastrianism and Christianity.\\n\\nAkbar was succeeded as emperor by his son, Prince Salim, later known as Jahangir.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create summary\n",
        "summary = summarizer(example_text, min_length=60, max_length=150)"
      ],
      "metadata": {
        "id": "YAbcpv1gKpgF"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary[0][\"summary_text\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "QA_wn4PqKs91",
        "outputId": "e4ab5d68-e8ad-4557-d59d-35f09034185a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Akbar the Great was the ruler of the Mughal Empire, one of the largest and most influential states in the Islamic world at the time of his death in 1605, at the age of 36, in a battle with his closest aide, Shah Jahan, at the Battle of Dar es Salaam, in what became known as the Battle of Dar es Salaam.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_text=\"\"\"S8UL Esports, a leading Indian esports and gaming organization, is preparing for the highly anticipated return of Battlegrounds Mobile India (BGMI) by planning to establish a new boot camp specifically for their BGMI lineup. The organization, known for housing successful esports athletes, creators, and streamers, has already invested significantly in their advanced gaming facility, the S8UL Gaming House. However, S8UL plans to establish a new boot camp specifically for their BGMI lineup when it makes a return and the current boot camp becomes insufficient.\n",
        "\n",
        "A new Boot Camp for BGMI players\n",
        "During livestreams, Animesh \"Thug\" Agrawal, co-founder of S8UL Esports, expressed his plans for the BGMI players, indicating the organization’s intention to create a separate boot camp. He mentioned the possibility of securing a flat exclusively for the BGMI players, offering them a comfortable environment to practice and stream their gameplay.\n",
        "\n",
        "\"Right now, the Pokemon Unite players have all gone back home, and if the game (BGMI) comes back, then we will be making another boot camp for them. We might get them a flat, especially for the BGMI players,\" he said.\n",
        "\n",
        "Lokesh \"Goldy\" Jain, another co-founder of S8UL Esports, echoed Thug's sentiment during a separate stream but added that the bootcamp will be a little smaller. “I won't be of the same scale of S8UL Gaming House 2.0. It would be flat where BGMI players will be set up with there streaming set-up to make them comfortable,” he said.\"\"\""
      ],
      "metadata": {
        "id": "dLHgMm6VQUN1"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create summary\n",
        "summary = summarizer(example_text, min_length=60, max_length=150)"
      ],
      "metadata": {
        "id": "ns7jTJEUQphm"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary[0][\"summary_text\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "CtP_BsVEQsHH",
        "outputId": "e05ec526-92ba-4a3f-d112-ad93ebdbd7d9"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'A leading Indian esports and gaming organization is preparing for the highly anticipated return of Mobile India (BGMI) by planning to establish a new boot camp specifically for their BGMI lineup. S8UL Esports, a leading Indian esports and gaming organization, is preparing for the highly anticipated return of Mobile India (BGMI) by planning to establish a new boot camp specifically for their BGMI lineup.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    }
  ]
}